{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Consulting Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Binary Customer Churn\n",
    "\n",
    "A marketing agency has many customers that use their service to produce ads for the client/customer websites. They've noticed that they have quite a bit of churn in clients. They basically randomly assign account managers right now, but want you to create a machine learning model that will help predict which customers will churn (stop buying their service) so that they can correctly assign the customers most at risk to churn an account manager. Luckily they have some historical data, can you help them out? Create a classification algorithm that will help classify whether or not a customer churned. Then the company can test this against incoming data for future customers to predict which customers will churn and assign them an account manager.\n",
    "\n",
    "The data is saved as customer_churn.csv. Here are the fields and their definitions:\n",
    "\n",
    "    Name : Name of the latest contact at Company\n",
    "    Age: Customer Age\n",
    "    Total_Purchase: Total Ads Purchased\n",
    "    Account_Manager: Binary 0=No manager, 1= Account manager assigned\n",
    "    Years: Totaly Years as a customer\n",
    "    Num_sites: Number of websites that use the service.\n",
    "    Onboard_date: Date that the name of the latest contact was onboarded\n",
    "    Location: Client HQ Address\n",
    "    Company: Name of Client Company\n",
    "    \n",
    "Once you've created the model and evaluated it, test out the model on some new data (you can think of this almost like a hold-out set) that your client has provided, saved under new_customers.csv. The client wants to know which customers are most likely to churn given this data (they don't have the label yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('logregdoc').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above are generally constant during the debugging process.   Below, the list of needed packages changes, hence it is kept isolated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This standardizes the data setup.  Used for both the training and evaluation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inhale_data(csv):\n",
    "    df = spark.read.csv(csv,inferSchema=True,header=True)\n",
    "    fields = [\"Age\",\"Total_Purchase\",\"Years\",\"Num_Sites\"]\n",
    "    assembler = VectorAssembler(inputCols=fields, outputCol=\"features\")\n",
    "    df = assembler.transform(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, several models are tried at different training/test set ratios.  The function returns an array where each element is a tupple of form (train_fraction, AUC_unvalidated, AUC_crossvalidated)\n",
    "\n",
    "NB: \n",
    "\n",
    "All values of AUC_unvalidated should be the same where train_fraction=1.0 for a logistic regression.\n",
    "\n",
    "AUC_crossvalidated is undefined at train_fraction=1.0 (manually set to -0.001 to avoid nan errors).\n",
    "\n",
    "One cannot have a model where train_fraction is 0.0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressive_challenges(df,train_fractions):\n",
    "    logregmod = LogisticRegression(featuresCol='features',labelCol='Churn')\n",
    "    AUC = []\n",
    "    for train_fraction in train_fractions:\n",
    "        test_fraction = 1.00 - train_fraction\n",
    "        \n",
    "        if train_fraction != 1.0:\n",
    "            train_df,test_df = df.randomSplit([train_fraction,test_fraction])\n",
    "        else:\n",
    "            train_df = df\n",
    "            \n",
    "        fit_model = logregmod.fit(train_df)\n",
    "        results = fit_model.transform(train_df)\n",
    "        my_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction',\n",
    "                                       labelCol='Churn')\n",
    "        AUC_unvalidated = my_eval.evaluate(results)\n",
    "        \n",
    "        if train_fraction != 1.0:\n",
    "            results = fit_model.transform(test_df)\n",
    "            my_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction',\n",
    "                                       labelCol='Churn')\n",
    "            AUC_crossvalidated = my_eval.evaluate(results)\n",
    "        else:\n",
    "            AUC_crossvalidated = -0.001\n",
    "            \n",
    "        AUC.append((train_fraction,AUC_unvalidated,AUC_crossvalidated))\n",
    "    return AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(train_df, eval_df):\n",
    "    logregmod = LogisticRegression(featuresCol='features',labelCol='Churn')\n",
    "    fit_model = logregmod.fit(train_df)\n",
    "    return fit_model.transform(eval_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = inhale_data(\"customer_churn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a simple trial model based on the numerics only.  \n",
    "\n",
    "Each two bit tupple is  (train_fraction, AUC_unvalidated, AUC_crossvalidated).\n",
    "\n",
    "Those results below are consistent with the results in the example presented.  They are not great for overall performance.  On the plus side, the difference between training over 10% and predicting 90% is not too different from training on 90% and predicting 10%.  \n",
    "\n",
    "If this was for real, we would break out the zip code from the address, pull the year from the date and try to make it better.  The example he gave does not do this.  \n",
    "\n",
    "NB: \n",
    "\n",
    "All values of AUC_unvalidated should be the same where train_fraction=1.0 for a logistic regression.\n",
    "\n",
    "AUC_crossvalidated is undefined at train_fraction=1.0 (manually set to -0.001 to avoid nan errors).\n",
    "\n",
    "One cannot have a model where train_fraction is 0.0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1, 0.8081791626095424, 0.7966744387289073),\n",
       " (0.1, 0.8453441295546559, 0.7824873237867052),\n",
       " (0.3, 0.7785117056856188, 0.7604199372056514),\n",
       " (0.3, 0.7474628274722681, 0.7143958389807535),\n",
       " (0.5, 0.7841130604288499, 0.7354534986113934),\n",
       " (0.5, 0.721175992412952, 0.7342711145951281),\n",
       " (0.7, 0.7770079435127979, 0.772340425531915),\n",
       " (0.7, 0.7831683168316832, 0.7612244897959183),\n",
       " (0.9, 0.7625238469307598, 0.8279411764705883),\n",
       " (1.0, 0.7633333333333333, -0.001),\n",
       " (1.0, 0.7633333333333333, -0.001)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fractions = [0.1,0.1,0.3,0.3,0.5,0.5,0.7,.7,0.9,1.0,1.0]\n",
    "progressive_challenges(df,train_fractions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do an eval on the unknown new customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = inhale_data(\"new_customers.csv\")\n",
    "eval_df = train_predict(df, eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+\n",
      "|         Company|prediction|\n",
      "+----------------+----------+\n",
      "|        King Ltd|       0.0|\n",
      "|   Cannon-Benson|       1.0|\n",
      "|Barron-Robertson|       1.0|\n",
      "|   Sexton-Golden|       1.0|\n",
      "|        Wood LLC|       0.0|\n",
      "|   Parks-Robbins|       1.0|\n",
      "+----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_df.select(['Company','prediction']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
